{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b648ee8",
   "metadata": {},
   "source": [
    "# Snowpark Basics HoL Part 1 - DataFrame Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed15903",
   "metadata": {},
   "source": [
    "## 1.1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e8402-54a4-47da-a6b2-da3d063f934a",
   "metadata": {},
   "source": [
    "### Imports\n",
    "These imports are from our local Python environment, snowparkbasics. Look out for F. and T. below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7410ce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make sure we do not get line breaks when doing show on wide dataframes\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f95920",
   "metadata": {},
   "source": [
    "### Create Snowpark Session\n",
    "Using a credentials file simplifies the HoL but is not recommended as good practice for development or production environments.\n",
    "<br> The Python connector documentation explains how to use other authentication methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d5f942-4348-4763-93de-0d0e5f7ed4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creds.json') as f:\n",
    "    connection_parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49090e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Database and schema: \"FROSTBYTE_TASTY_BYTES_V2\".\"RAW_POS\"\n",
      "Current Warehouse: \"TASTY_DE_WH\"\n"
     ]
    }
   ],
   "source": [
    "session = Session.builder.configs(connection_parameters).create()\n",
    "print(f\"Current Database and schema: {session.get_fully_qualified_current_schema()}\")\n",
    "print(f\"Current Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e003c-cf5c-4d1f-aa30-56da1ce2c296",
   "metadata": {},
   "source": [
    "### Modifying our Session\n",
    "We can use **session.sql** to issue any 'SQL' command. Note that due to lazy evaluation, typically nothing will happen without a show() or collect()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39be44fd-fd07-47c3-a546-2cbb00b3d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Warehouse: \"TASTY_DEV_WH\"\n"
     ]
    }
   ],
   "source": [
    "session.sql(\"USE WAREHOUSE TASTY_DEV_WH\").collect()\n",
    "print(f\"Current Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84354485-ebe6-4220-aa88-3392468477c9",
   "metadata": {},
   "source": [
    "However, session also has a number of methods such as **use_warehouse()**. These *are* run immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62852de0-513e-4685-b1f2-c386293e4c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Warehouse: \"TASTY_DE_WH\"\n"
     ]
    }
   ],
   "source": [
    "session.use_warehouse(\"TASTY_DE_WH\")\n",
    "print(f\"Current Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c0c26",
   "metadata": {},
   "source": [
    "## 1.2 Loading a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7c8c2-5fc7-4ee7-9f55-6468179d7fee",
   "metadata": {},
   "source": [
    "### Pandas DataFrames from CSV\n",
    "Let's create a Pandas dataframe directly from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e6d1164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Creating a Pandas DataFrame - the order header csv is in fact the data from only one truck!!\n",
    "pandas_truck_df = pd.read_csv('data/truck.csv')\n",
    "pandas_header_df = pd.read_csv('data/header.csv')\n",
    "print(type(pandas_truck_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e71a5d8-269d-433e-be91-aef35aa342b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRUCK_ID</th>\n",
       "      <th>MENU_TYPE_ID</th>\n",
       "      <th>PRIMARY_CITY</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ISO_REGION</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>ISO_COUNTRY_CODE</th>\n",
       "      <th>FRANCHISE_FLAG</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>EV_FLAG</th>\n",
       "      <th>FRANCHISE_ID</th>\n",
       "      <th>TRUCK_OPENING_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>Freightliner</td>\n",
       "      <td>MT45 Utilimaster</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>P30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>Custom</td>\n",
       "      <td>Van</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>Airstream</td>\n",
       "      <td>Trailer</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>392</td>\n",
       "      <td>2</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Madrid provincia</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>396</td>\n",
       "      <td>6</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Madrid provincia</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>Freightliner</td>\n",
       "      <td>MT45 Utilimaster</td>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>419</td>\n",
       "      <td>14</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Barcelona provincia</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Airstream</td>\n",
       "      <td>Trailer</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>427</td>\n",
       "      <td>7</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Cairo Governorate</td>\n",
       "      <td>Al Qahirah</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>EG</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>15</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>Western Cape</td>\n",
       "      <td>Western Cape</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>ZA</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TRUCK_ID  MENU_TYPE_ID PRIMARY_CITY               REGION    ISO_REGION  \\\n",
       "0           2             2    San Mateo           California            CA   \n",
       "1           3             3    San Mateo           California            CA   \n",
       "2           4             4    San Mateo           California            CA   \n",
       "3           5             5    San Mateo           California            CA   \n",
       "4           6             6    San Mateo           California            CA   \n",
       "..        ...           ...          ...                  ...           ...   \n",
       "445       392             2       Madrid     Madrid provincia        Madrid   \n",
       "446       396             6       Madrid     Madrid provincia        Madrid   \n",
       "447       419            14    Barcelona  Barcelona provincia     Barcelona   \n",
       "448       427             7        Cairo    Cairo Governorate    Al Qahirah   \n",
       "449       450            15    Cape Town         Western Cape  Western Cape   \n",
       "\n",
       "           COUNTRY ISO_COUNTRY_CODE  FRANCHISE_FLAG  YEAR          MAKE  \\\n",
       "0    United States               US               0  2015         Ford_   \n",
       "1    United States               US               1  2004  Freightliner   \n",
       "2    United States               US               1  1997     Chevrolet   \n",
       "3    United States               US               1  2010        Custom   \n",
       "4    United States               US               1  2010     Airstream   \n",
       "..             ...              ...             ...   ...           ...   \n",
       "445          Spain               ES               0  2010         Ford_   \n",
       "446          Spain               ES               1  2005  Freightliner   \n",
       "447          Spain               ES               1  2015     Airstream   \n",
       "448          Egypt               EG               1  2005         Ford_   \n",
       "449   South Africa               ZA               1  2009         Ford_   \n",
       "\n",
       "                MODEL  EV_FLAG  FRANCHISE_ID TRUCK_OPENING_DATE  \n",
       "0            Step Van        0             1         2015-07-01  \n",
       "1    MT45 Utilimaster        0             2         2015-11-01  \n",
       "2                 P30        1             3         2019-02-01  \n",
       "3                 Van        1             4         2020-04-01  \n",
       "4             Trailer        0             5         2015-07-01  \n",
       "..                ...      ...           ...                ...  \n",
       "445          Step Van        0             1         2014-12-29  \n",
       "446  MT45 Utilimaster        1           298         2014-12-29  \n",
       "447           Trailer        0           312         2014-12-29  \n",
       "448          Step Van        0           319         2014-12-29  \n",
       "449          Step Van        0           336         2014-12-29  \n",
       "\n",
       "[450 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the Pandas dataframe\n",
    "pandas_truck_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9da18-f43d-487f-b041-d5223b99395c",
   "metadata": {},
   "source": [
    "### Snowpark DataFrames from Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d391b0-58e0-4b39-90bb-27bb4ce78a22",
   "metadata": {},
   "source": [
    "The Snowpark **Table** class is a child of the **DataFrame** class.  We can define a dataframe based on a table very simply.\n",
    "<br> (We'll look at loading file data into tables in Part 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623695f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'snowflake.snowpark.table.Table'>\n"
     ]
    }
   ],
   "source": [
    "snowpark_truck_df = session.table('TRUCK')\n",
    "snowpark_header_df = session.table('ORDER_HEADER')\n",
    "print(type(snowpark_truck_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a48f9-ed44-4974-9493-137c303d328c",
   "metadata": {},
   "source": [
    "### Comparing DataFrames\n",
    "Compare sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2d4f6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size in MB of Pandas Truck DataFrame in Memory:  0.25\n",
      "Size in MB of Snowpark Truck DataFrame in Memory:  0.0\n",
      "Size in MB of Pandas Header DataFrame in Memory:  132.66\n",
      "Size in MB of Snowpark Header DataFrame in Memory:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Size in MB of Pandas Truck DataFrame in Memory: \",\n",
    "    np.round(sys.getsizeof(pandas_truck_df) / (1024.0**2), 2),\n",
    ")\n",
    "print(\n",
    "    \"Size in MB of Snowpark Truck DataFrame in Memory: \",\n",
    "    np.round(sys.getsizeof(snowpark_truck_df) / (1024.0**2), 2),\n",
    ")\n",
    "print(\n",
    "    \"Size in MB of Pandas Header DataFrame in Memory: \",\n",
    "    np.round(sys.getsizeof(pandas_header_df) / (1024.0**2), 2),\n",
    ")\n",
    "print(\n",
    "    \"Size in MB of Snowpark Header DataFrame in Memory: \",\n",
    "    np.round(sys.getsizeof(snowpark_header_df) / (1024.0**2), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea0fc5",
   "metadata": {},
   "source": [
    "The only thing stored in a Snowpark DataFrame is the SQL needed to return data.\n",
    "<br>Trying to manipulate even one truck's worth of order headers in Pandas starts to get 'interesting'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac7d60-30d6-412b-baf8-b6010597e90c",
   "metadata": {},
   "source": [
    "Now, what is going on under the covers? You might want to log into your Snowflake account as the same user and review Snowsight Query History. But you can also use this DataFrame attribute from Snowpark..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43db7633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT  *  FROM (ORDER_HEADER)'], 'post_actions': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowpark_header_df.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf44c3",
   "metadata": {},
   "source": [
    "A Snowpark DataFrame can be converted to a Pandas DataFrame. This will pull the data from Snowflake into local memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ec1ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRUCK_ID</th>\n",
       "      <th>MENU_TYPE_ID</th>\n",
       "      <th>PRIMARY_CITY</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ISO_REGION</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>ISO_COUNTRY_CODE</th>\n",
       "      <th>FRANCHISE_FLAG</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>EV_FLAG</th>\n",
       "      <th>FRANCHISE_ID</th>\n",
       "      <th>TRUCK_OPENING_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>Freightliner</td>\n",
       "      <td>MT45 Utilimaster</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>P30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>Custom</td>\n",
       "      <td>Van</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>Airstream</td>\n",
       "      <td>Trailer</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>392</td>\n",
       "      <td>2</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Madrid provincia</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>396</td>\n",
       "      <td>6</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Madrid provincia</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>Freightliner</td>\n",
       "      <td>MT45 Utilimaster</td>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>419</td>\n",
       "      <td>14</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Barcelona provincia</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Airstream</td>\n",
       "      <td>Trailer</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>427</td>\n",
       "      <td>7</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Cairo Governorate</td>\n",
       "      <td>Al Qahirah</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>EG</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>15</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>Western Cape</td>\n",
       "      <td>Western Cape</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>ZA</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TRUCK_ID  MENU_TYPE_ID PRIMARY_CITY               REGION    ISO_REGION  \\\n",
       "0           2             2    San Mateo           California            CA   \n",
       "1           3             3    San Mateo           California            CA   \n",
       "2           4             4    San Mateo           California            CA   \n",
       "3           5             5    San Mateo           California            CA   \n",
       "4           6             6    San Mateo           California            CA   \n",
       "..        ...           ...          ...                  ...           ...   \n",
       "445       392             2       Madrid     Madrid provincia        Madrid   \n",
       "446       396             6       Madrid     Madrid provincia        Madrid   \n",
       "447       419            14    Barcelona  Barcelona provincia     Barcelona   \n",
       "448       427             7        Cairo    Cairo Governorate    Al Qahirah   \n",
       "449       450            15    Cape Town         Western Cape  Western Cape   \n",
       "\n",
       "           COUNTRY ISO_COUNTRY_CODE  FRANCHISE_FLAG  YEAR          MAKE  \\\n",
       "0    United States               US               0  2015         Ford_   \n",
       "1    United States               US               1  2004  Freightliner   \n",
       "2    United States               US               1  1997     Chevrolet   \n",
       "3    United States               US               1  2010        Custom   \n",
       "4    United States               US               1  2010     Airstream   \n",
       "..             ...              ...             ...   ...           ...   \n",
       "445          Spain               ES               0  2010         Ford_   \n",
       "446          Spain               ES               1  2005  Freightliner   \n",
       "447          Spain               ES               1  2015     Airstream   \n",
       "448          Egypt               EG               1  2005         Ford_   \n",
       "449   South Africa               ZA               1  2009         Ford_   \n",
       "\n",
       "                MODEL  EV_FLAG  FRANCHISE_ID TRUCK_OPENING_DATE  \n",
       "0            Step Van        0             1         2015-07-01  \n",
       "1    MT45 Utilimaster        0             2         2015-11-01  \n",
       "2                 P30        1             3         2019-02-01  \n",
       "3                 Van        1             4         2020-04-01  \n",
       "4             Trailer        0             5         2015-07-01  \n",
       "..                ...      ...           ...                ...  \n",
       "445          Step Van        0             1         2014-12-29  \n",
       "446  MT45 Utilimaster        1           298         2014-12-29  \n",
       "447           Trailer        0           312         2014-12-29  \n",
       "448          Step Van        0           319         2014-12-29  \n",
       "449          Step Van        0           336         2014-12-29  \n",
       "\n",
       "[450 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_truck_df2 = snowpark_truck_df.to_pandas()\n",
    "pandas_truck_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e707de",
   "metadata": {},
   "source": [
    "Both our Pandas DataFrames have the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db95baaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((450, 14), (450, 14))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_truck_df.shape, pandas_truck_df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f42bc",
   "metadata": {},
   "source": [
    "### Displaying a Snowpark DataFrame\n",
    "Defining and modifying a Snowpark dataframe does not generally result in any activity within Snowflake - lazy evaluation, similar to Spark.\n",
    "The **show** method causes a query to be generated and sent and data returned - by default just 10 rows.\n",
    "In contrast **toPandas** or **to_pandas** will retrieve the whole dataset unless you set a **limit**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa02b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"ORDER_ID\"  |\"TRUCK_ID\"  |\"LOCATION_ID\"  |\"CUSTOMER_ID\"  |\"DISCOUNT_ID\"  |\"SHIFT_ID\"  |\"SHIFT_START_TIME\"  |\"SHIFT_END_TIME\"  |\"ORDER_CHANNEL\"  |\"ORDER_TS\"                  |\"SERVED_TS\"  |\"ORDER_CURRENCY\"  |\"ORDER_AMOUNT\"  |\"ORDER_TAX_AMOUNT\"  |\"ORDER_DISCOUNT_AMOUNT\"  |\"ORDER_TOTAL\"  |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|32723511    |140         |3193.0         |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 11:00:00.355000  |NULL         |USD               |16.3600         |NULL                |NULL                     |16.3600        |\n",
      "|32723512    |224         |6654.0         |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 13:11:52.893000  |NULL         |USD               |7.9300          |NULL                |NULL                     |7.9300         |\n",
      "|32723513    |415         |13900.0        |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 10:47:57.132000  |NULL         |USD               |2.6000          |NULL                |NULL                     |2.6000         |\n",
      "|32723514    |300         |7837.0         |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 14:23:58.355000  |NULL         |USD               |3.1700          |NULL                |NULL                     |3.1700         |\n",
      "|32723515    |216         |13815.0        |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 09:51:18.599000  |NULL         |USD               |1.4400          |NULL                |NULL                     |1.4400         |\n",
      "|32723516    |61          |1280.0         |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 10:17:15.885000  |NULL         |USD               |1.8000          |NULL                |NULL                     |1.8000         |\n",
      "|32723517    |298         |10101.0        |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 14:40:59.997000  |NULL         |USD               |43.6700         |NULL                |NULL                     |43.6700        |\n",
      "|32723518    |256         |14472.0        |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 14:20:01.203000  |NULL         |USD               |20.1200         |NULL                |NULL                     |20.1200        |\n",
      "|32723519    |74          |15203.0        |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 14:37:38.972000  |NULL         |USD               |7.9300          |NULL                |NULL                     |7.9300         |\n",
      "|32723520    |111         |5379.0         |NULL           |NULL           |1           |09:00:00            |15:00:00          |NULL             |2017-08-15 12:00:02.708000  |NULL         |USD               |3.4000          |NULL                |NULL                     |3.4000         |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_ID</th>\n",
       "      <th>TRUCK_ID</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>DISCOUNT_ID</th>\n",
       "      <th>SHIFT_ID</th>\n",
       "      <th>SHIFT_START_TIME</th>\n",
       "      <th>SHIFT_END_TIME</th>\n",
       "      <th>ORDER_CHANNEL</th>\n",
       "      <th>ORDER_TS</th>\n",
       "      <th>SERVED_TS</th>\n",
       "      <th>ORDER_CURRENCY</th>\n",
       "      <th>ORDER_AMOUNT</th>\n",
       "      <th>ORDER_TAX_AMOUNT</th>\n",
       "      <th>ORDER_DISCOUNT_AMOUNT</th>\n",
       "      <th>ORDER_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32723511</td>\n",
       "      <td>140</td>\n",
       "      <td>3193.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-08-15 11:00:00.355</td>\n",
       "      <td>None</td>\n",
       "      <td>USD</td>\n",
       "      <td>16.36</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32723512</td>\n",
       "      <td>224</td>\n",
       "      <td>6654.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-08-15 13:11:52.893</td>\n",
       "      <td>None</td>\n",
       "      <td>USD</td>\n",
       "      <td>7.93</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32723513</td>\n",
       "      <td>415</td>\n",
       "      <td>13900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-08-15 10:47:57.132</td>\n",
       "      <td>None</td>\n",
       "      <td>USD</td>\n",
       "      <td>2.60</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32723514</td>\n",
       "      <td>300</td>\n",
       "      <td>7837.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-08-15 14:23:58.355</td>\n",
       "      <td>None</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.17</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32723515</td>\n",
       "      <td>216</td>\n",
       "      <td>13815.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-08-15 09:51:18.599</td>\n",
       "      <td>None</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.44</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ORDER_ID  TRUCK_ID  LOCATION_ID  CUSTOMER_ID DISCOUNT_ID  SHIFT_ID  \\\n",
       "0  32723511       140       3193.0          NaN        None         1   \n",
       "1  32723512       224       6654.0          NaN        None         1   \n",
       "2  32723513       415      13900.0          NaN        None         1   \n",
       "3  32723514       300       7837.0          NaN        None         1   \n",
       "4  32723515       216      13815.0          NaN        None         1   \n",
       "\n",
       "  SHIFT_START_TIME SHIFT_END_TIME ORDER_CHANNEL                ORDER_TS  \\\n",
       "0         09:00:00       15:00:00          None 2017-08-15 11:00:00.355   \n",
       "1         09:00:00       15:00:00          None 2017-08-15 13:11:52.893   \n",
       "2         09:00:00       15:00:00          None 2017-08-15 10:47:57.132   \n",
       "3         09:00:00       15:00:00          None 2017-08-15 14:23:58.355   \n",
       "4         09:00:00       15:00:00          None 2017-08-15 09:51:18.599   \n",
       "\n",
       "  SERVED_TS ORDER_CURRENCY  ORDER_AMOUNT ORDER_TAX_AMOUNT  \\\n",
       "0      None            USD         16.36             None   \n",
       "1      None            USD          7.93             None   \n",
       "2      None            USD          2.60             None   \n",
       "3      None            USD          3.17             None   \n",
       "4      None            USD          1.44             None   \n",
       "\n",
       "  ORDER_DISCOUNT_AMOUNT  ORDER_TOTAL  \n",
       "0                  None        16.36  \n",
       "1                  None         7.93  \n",
       "2                  None         2.60  \n",
       "3                  None         3.17  \n",
       "4                  None         1.44  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowpark_header_df.show() # <- has a default limit of 10, and prints the data out\n",
    "snowpark_header_df.limit(5).toPandas() # <- collects first 5 rows and displays as pandas-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93780fd5-3196-456e-8046-bf3dd1af2b33",
   "metadata": {},
   "source": [
    "In fact, you don't need to give your dataframe a name just to examine the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c628016-f381-47fd-8c75-950271d15cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"LOCATION_ID\"  |\"PLACEKEY\"           |\"LOCATION\"                                |\"CITY\"   |\"REGION\"  |\"ISO_COUNTRY_CODE\"  |\"COUNTRY\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|5048           |zzy-222@53v-7xj-nqz  |L'Enclos des Oiseaux                      |Paris    |Paris     |FR                  |France     |\n",
      "|9612           |zzy-224@53v-7y8-jn5  |Esplanade Jacques Chaban Delmas           |Paris    |Paris     |FR                  |France     |\n",
      "|10386          |zzy-225@53v-8dm-bff  |College Boris Vian                        |Paris    |Paris     |FR                  |France     |\n",
      "|10875          |zzy-226@53v-7yb-3dv  |Refectoire des Cordeliers                 |Paris    |Paris     |FR                  |France     |\n",
      "|12260          |zzy-22c@53v-7yb-47q  |Square Paul Painleve                      |Paris    |Paris     |FR                  |France     |\n",
      "|12594          |zzy-22f@53v-7tg-5zz  |Petits Fils                               |Paris    |Paris     |FR                  |France     |\n",
      "|12749          |zzy-22g@53v-7xk-4d9  |Corps Blancs de Jerome Mesnager           |Paris    |Paris     |FR                  |France     |\n",
      "|5012           |zzy-222@53v-7vq-35z  |Pelouse de Reuilly                        |Paris    |Paris     |FR                  |France     |\n",
      "|14256          |zzy-23c@53v-8dp-7t9  |Ecole Superieure d'Orthodontie            |Paris    |Paris     |FR                  |France     |\n",
      "|4509           |zzy-222@528-wcn-pjv  |Reincke Gedachtnis Haus Betreutes Wohnen  |Hamburg  |Hamburg   |DE                  |Germany    |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.table(\"RAW_POS.LOCATION\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea5929-551b-4c7c-826c-284bee7040fa",
   "metadata": {},
   "source": [
    "### Simple DataFrame Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd4963-e678-4e0a-820f-4dc3c53cec37",
   "metadata": {},
   "source": [
    "The **count** method on a DataFrame will return the number of rows. This also triggers a query to Snowflake. *(Cf pyspark.sql.DataFrame.count())*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05786ed4-aaaa-4d7a-a03c-5758fdbff2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84240060"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows in dataset\n",
    "snowpark_header_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6eac9-5af8-46b0-b8a9-12f6d92bfacd",
   "metadata": {},
   "source": [
    "We can get an idea of the structure from the **schema** attribute.  *(Cf pyspark.sql.DataFrame.schema)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b67e604-0dbb-4b91-a90d-1d81c447f130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ORDER_ID', LongType(), nullable=True), StructField('TRUCK_ID', LongType(), nullable=True), StructField('LOCATION_ID', DoubleType(), nullable=True), StructField('CUSTOMER_ID', LongType(), nullable=True), StructField('DISCOUNT_ID', StringType(16777216), nullable=True), StructField('SHIFT_ID', LongType(), nullable=True), StructField('SHIFT_START_TIME', TimeType(), nullable=True), StructField('SHIFT_END_TIME', TimeType(), nullable=True), StructField('ORDER_CHANNEL', StringType(16777216), nullable=True), StructField('ORDER_TS', TimestampType(tz=ntz), nullable=True), StructField('SERVED_TS', StringType(16777216), nullable=True), StructField('ORDER_CURRENCY', StringType(3), nullable=True), StructField('ORDER_AMOUNT', DecimalType(38, 4), nullable=True), StructField('ORDER_TAX_AMOUNT', StringType(16777216), nullable=True), StructField('ORDER_DISCOUNT_AMOUNT', StringType(16777216), nullable=True), StructField('ORDER_TOTAL', DecimalType(38, 4), nullable=True)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_schema = snowpark_header_df.schema\n",
    "header_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c057b-8afb-4694-9e77-418c79e09694",
   "metadata": {},
   "source": [
    "Using the **describe** method will return some basic statistics for all numeric and string columns.  *(Cf pyspark.sql.DataFrame.describe())*\n",
    "<br>Note that this does real work inside Snowflake! The statistical values are not necessarily meaningful for all columns.\n",
    "<br>Can you find the maximum order value in the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe4ae674-9c32-4472-9e4a-183f691be740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SUMMARY\"  |\"ORDER_ID\"         |\"TRUCK_ID\"          |\"LOCATION_ID\"      |\"CUSTOMER_ID\"      |\"DISCOUNT_ID\"  |\"SHIFT_ID\"          |\"ORDER_CHANNEL\"  |\"SERVED_TS\"  |\"ORDER_CURRENCY\"  |\"ORDER_AMOUNT\"      |\"ORDER_TAX_AMOUNT\"  |\"ORDER_DISCOUNT_AMOUNT\"  |\"ORDER_TOTAL\"       |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|count      |84240060.0         |84240060.0          |84240060.0         |7174101.0          |0              |84240060.0          |0                |0            |84240060          |84240060.0          |0                   |0                        |84240060.0          |\n",
      "|max        |142439672.0        |450.0               |15517.0            |222540.0           |NULL           |1.0                 |NULL             |NULL         |USD               |400.22              |NULL                |NULL                     |400.22              |\n",
      "|min        |1.0                |1.0                 |1001.0             |1.0                |NULL           |0.0                 |NULL             |NULL         |USD               |0.51                |NULL                |NULL                     |0.51                |\n",
      "|mean       |67755456.109222    |241.647524          |8326.638014206068  |116716.760135      |NULL           |0.454925            |NULL             |NULL         |NULL              |21.1425468046       |NULL                |NULL                     |21.1425468046       |\n",
      "|stddev     |38108734.34062458  |117.93384966581901  |3844.139455287346  |66017.30408548976  |NULL           |0.4979638541099143  |NULL             |NULL         |NULL              |21.138983981983927  |NULL                |NULL                     |21.138983981983927  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating various statistics per column\n",
    "snowpark_header_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7848e9",
   "metadata": {},
   "source": [
    "## 1.3 Managing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f43c9f-fc7f-46fe-b90a-ebac3a98d497",
   "metadata": {},
   "source": [
    "### Selecting Columns\n",
    "There are several ways to **select** specific columns, including **functions.col** and **DataFrame.col**. \n",
    "<br>The latter two are needed in several stuations to avoid ambiguities with string constants. \n",
    "<br>What do you notice about the four results below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79a577f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "|\"ORDER_ID\"  |\"TRUCK_ID\"  |\"LOCATION_ID\"  |\"ORDER_AMOUNT\"  |\"ORDER_TS\"                  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "|32723511    |140         |3193.0         |16.3600         |2017-08-15 11:00:00.355000  |\n",
      "|32723512    |224         |6654.0         |7.9300          |2017-08-15 13:11:52.893000  |\n",
      "|32723513    |415         |13900.0        |2.6000          |2017-08-15 10:47:57.132000  |\n",
      "|32723514    |300         |7837.0         |3.1700          |2017-08-15 14:23:58.355000  |\n",
      "|32723515    |216         |13815.0        |1.4400          |2017-08-15 09:51:18.599000  |\n",
      "|32723516    |61          |1280.0         |1.8000          |2017-08-15 10:17:15.885000  |\n",
      "|32723517    |298         |10101.0        |43.6700         |2017-08-15 14:40:59.997000  |\n",
      "|32723518    |256         |14472.0        |20.1200         |2017-08-15 14:20:01.203000  |\n",
      "|32723519    |74          |15203.0        |7.9300          |2017-08-15 14:37:38.972000  |\n",
      "|32723520    |111         |5379.0         |3.4000          |2017-08-15 12:00:02.708000  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\"ORDER_ID\"  |\"TRUCK_ID\"  |\"LOCATION_ID\"  |\"ORDER_AMOUNT\"  |\"ORDER_TS\"                  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "|32723511    |140         |3193.0         |16.3600         |2017-08-15 11:00:00.355000  |\n",
      "|32723512    |224         |6654.0         |7.9300          |2017-08-15 13:11:52.893000  |\n",
      "|32723513    |415         |13900.0        |2.6000          |2017-08-15 10:47:57.132000  |\n",
      "|32723514    |300         |7837.0         |3.1700          |2017-08-15 14:23:58.355000  |\n",
      "|32723515    |216         |13815.0        |1.4400          |2017-08-15 09:51:18.599000  |\n",
      "|32723516    |61          |1280.0         |1.8000          |2017-08-15 10:17:15.885000  |\n",
      "|32723517    |298         |10101.0        |43.6700         |2017-08-15 14:40:59.997000  |\n",
      "|32723518    |256         |14472.0        |20.1200         |2017-08-15 14:20:01.203000  |\n",
      "|32723519    |74          |15203.0        |7.9300          |2017-08-15 14:37:38.972000  |\n",
      "|32723520    |111         |5379.0         |3.4000          |2017-08-15 12:00:02.708000  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\"ORDER_ID\"  |\"TRUCK_ID\"  |\"LOCATION_ID\"  |\"ORDER_AMOUNT\"  |\"ORDER_TS\"                  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "|32723511    |140         |3193.0         |16.3600         |2017-08-15 11:00:00.355000  |\n",
      "|32723512    |224         |6654.0         |7.9300          |2017-08-15 13:11:52.893000  |\n",
      "|32723513    |415         |13900.0        |2.6000          |2017-08-15 10:47:57.132000  |\n",
      "|32723514    |300         |7837.0         |3.1700          |2017-08-15 14:23:58.355000  |\n",
      "|32723515    |216         |13815.0        |1.4400          |2017-08-15 09:51:18.599000  |\n",
      "|32723516    |61          |1280.0         |1.8000          |2017-08-15 10:17:15.885000  |\n",
      "|32723517    |298         |10101.0        |43.6700         |2017-08-15 14:40:59.997000  |\n",
      "|32723518    |256         |14472.0        |20.1200         |2017-08-15 14:20:01.203000  |\n",
      "|32723519    |74          |15203.0        |7.9300          |2017-08-15 14:37:38.972000  |\n",
      "|32723520    |111         |5379.0         |3.4000          |2017-08-15 12:00:02.708000  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\"ORDER_ID\"  |\"TRUCK_ID\"  |\"LOCATION_ID\"  |\"ORDER_AMOUNT\"  |\"ORDER_TS\"                  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "|32723511    |140         |3193.0         |16.3600         |2017-08-15 11:00:00.355000  |\n",
      "|32723512    |224         |6654.0         |7.9300          |2017-08-15 13:11:52.893000  |\n",
      "|32723513    |415         |13900.0        |2.6000          |2017-08-15 10:47:57.132000  |\n",
      "|32723514    |300         |7837.0         |3.1700          |2017-08-15 14:23:58.355000  |\n",
      "|32723515    |216         |13815.0        |1.4400          |2017-08-15 09:51:18.599000  |\n",
      "|32723516    |61          |1280.0         |1.8000          |2017-08-15 10:17:15.885000  |\n",
      "|32723517    |298         |10101.0        |43.6700         |2017-08-15 14:40:59.997000  |\n",
      "|32723518    |256         |14472.0        |20.1200         |2017-08-15 14:20:01.203000  |\n",
      "|32723519    |74          |15203.0        |7.9300          |2017-08-15 14:37:38.972000  |\n",
      "|32723520    |111         |5379.0         |3.4000          |2017-08-15 12:00:02.708000  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "header_df1 = snowpark_header_df.select('ORDER_ID','TRUCK_ID','LOCATION_ID','ORDER_AMOUNT','ORDER_TS')\n",
    "header_df2 = snowpark_header_df[['ORDER_ID','TRUCK_ID','LOCATION_ID','ORDER_AMOUNT','ORDER_TS']] # -> pandas-like selection\n",
    "header_df3 = snowpark_header_df.select(F.col(\"ORDER_ID\"),F.col(\"truck_id\"),F.col(\"location_id\"),\n",
    "                                       F.col(\"order_amount\"), F.col(\"order_ts\"))\n",
    "header_df4 = snowpark_header_df.select(snowpark_header_df.col('ORDER_ID'),snowpark_header_df.col('TRUCK_ID'),\n",
    "                                       snowpark_header_df.col('LOCATION_ID'),snowpark_header_df.col('ORDER_AMOUNT'),\n",
    "                                       snowpark_header_df.col('ORDER_TS'))\n",
    "header_df1.show()\n",
    "header_df2.show()\n",
    "header_df3.show()\n",
    "header_df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50703ac-a1f1-4961-b948-0f9109655ad5",
   "metadata": {},
   "source": [
    "In general in Python single and double quotes are interchangeable. Best practice is to choose one and stick with it (unlike in this HoL). \n",
    "<br>Note that in all the examples above, the names are implicitly converted to uppercase.\n",
    "<br>To handle identifiers with lowercase you need to add explicit double quotes within the string, either within single quotes as below, or with an escape character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba089853-4704-4e59-a32b-546c925ab550",
   "metadata": {},
   "outputs": [
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01b0a210-0404-d76a-001b-7a8701edc7d6: 000904 (42000): SQL compilation error: error line 1 at position 7\ninvalid identifier '\"order_id\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#The following statement should fail\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msnowpark_header_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morder_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTRUCK_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLOCATION_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mORDER_AMOUNT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mORDER_TS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/telemetry.py:139\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 139\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     plan \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_plan\n\u001b[1;32m    141\u001b[0m     api_calls \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39mplan\u001b[38;5;241m.\u001b[39mapi_calls,\n\u001b[1;32m    143\u001b[0m         {TelemetryField\u001b[38;5;241m.\u001b[39mNAME\u001b[38;5;241m.\u001b[39mvalue: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    144\u001b[0m     ]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/dataframe.py:2855\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, max_width, statement_params)\u001b[0m\n\u001b[1;32m   2836\u001b[0m \u001b[38;5;129m@df_collect_api_telemetry\u001b[39m\n\u001b[1;32m   2837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\n\u001b[1;32m   2838\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2842\u001b[0m     statement_params: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2843\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates this DataFrame and prints out the first ``n`` rows with the\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;124;03m    specified maximum number of characters per column.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2852\u001b[0m \u001b[38;5;124;03m        statement_params: Dictionary of statement level parameters to be set while executing this action.\u001b[39;00m\n\u001b[1;32m   2853\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2854\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m-> 2855\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_or_update_statement_params_with_query_tag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[43m                \u001b[49m\u001b[43mSKIP_LEVELS_TWO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2864\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/dataframe.py:2973\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, max_width, **kwargs)\u001b[0m\n\u001b[1;32m   2970\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plan\u001b[38;5;241m.\u001b[39mqueries[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m   2972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sql_select_statement(query):\n\u001b[0;32m-> 2973\u001b[0m     result, meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_and_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2977\u001b[0m     res, meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mget_result_and_metadata(\n\u001b[1;32m   2978\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plan, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2979\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:592\u001b[0m, in \u001b[0;36mServerConnection.get_result_and_metadata\u001b[0;34m(self, plan, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result_and_metadata\u001b[39m(\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m, plan: SnowflakePlan, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    591\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Row], List[Attribute]]:\n\u001b[0;32m--> 592\u001b[0m     result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m     result \u001b[38;5;241m=\u001b[39m result_set_to_rows(result_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    594\u001b[0m     meta \u001b[38;5;241m=\u001b[39m convert_result_meta_to_attribute(result_meta)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:176\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m         ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    174\u001b[0m             e\n\u001b[1;32m    175\u001b[0m         )\n\u001b[0;32m--> 176\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    179\u001b[0m         e\n\u001b[1;32m    180\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:111\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:552\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m holder, id_ \u001b[38;5;129;01min\u001b[39;00m placeholders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    551\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 552\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_job_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    566\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mquery_id\n\u001b[1;32m    567\u001b[0m )\n\u001b[1;32m    568\u001b[0m result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor\u001b[38;5;241m.\u001b[39mdescription\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:102\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m     99\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:96\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m     99\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    100\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:366\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m         query_id_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py:347\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_statement_params\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 347\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    349\u001b[0m         QueryRecord(results_cursor\u001b[38;5;241m.\u001b[39msfqid, results_cursor\u001b[38;5;241m.\u001b[39mquery)\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    351\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecute query [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_cursor\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/connector/cursor.py:920\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[1;32m    916\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    917\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m    919\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m--> 920\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    269\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    298\u001b[0m             error_class,\n\u001b[1;32m    299\u001b[0m             error_value,\n\u001b[1;32m    300\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/snowparkbasics/lib/python3.10/site-packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    219\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01b0a210-0404-d76a-001b-7a8701edc7d6: 000904 (42000): SQL compilation error: error line 1 at position 7\ninvalid identifier '\"order_id\"'"
     ]
    }
   ],
   "source": [
    "#The following statement should fail\n",
    "snowpark_header_df.select(F.col('\"order_id\"'),F.col(\"TRUCK_ID\"),F.col(\"LOCATION_ID\"),F.col(\"ORDER_AMOUNT\"), F.col(\"ORDER_TS\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35149f79-6e0d-45af-a522-bf44538e6084",
   "metadata": {},
   "source": [
    "### Casting, Aliasing and In-Line Calculations\n",
    "We can **cast** the column datatypes. For example ORDER_AMOUNT could be cast to NUMBER(36,2). Alternatively we have functions like **to_date**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1580443c-7d5a-4ac4-9d57-821036f61f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "|\"ORDER_ID\"  |\"CAST (\"\"ORDER_AMOUNT\"\" AS NUMBER(36, 2))\"  |\"TO_DATE(\"\"ORDER_TS\"\")\"  |\n",
      "-------------------------------------------------------------------------------------\n",
      "|120684509   |17.58                                       |2022-09-08               |\n",
      "|120684510   |16.88                                       |2022-09-08               |\n",
      "|120684511   |9.68                                        |2022-09-08               |\n",
      "|120684512   |64.05                                       |2022-09-08               |\n",
      "|120684513   |10.20                                       |2022-09-08               |\n",
      "|120684514   |13.12                                       |2022-09-08               |\n",
      "|120684515   |12.03                                       |2022-09-08               |\n",
      "|120684516   |16.22                                       |2022-09-08               |\n",
      "|120684517   |37.66                                       |2022-09-08               |\n",
      "|120684518   |52.49                                       |2022-09-08               |\n",
      "-------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "header_df1 = snowpark_header_df.select(F.col(\"ORDER_ID\"),F.col('ORDER_AMOUNT').cast(T.DecimalType(36,2)),\n",
    "                                       F.to_date(F.col('ORDER_TS')))\n",
    "header_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df34c7-8ad1-4aeb-8bd1-2a75e6bac40d",
   "metadata": {},
   "source": [
    "That's a bit ugly. Let's alias those columns...  **alias**, **name** and **as_** all achieve the same effect. *(Cf pyspark alias or name)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a271172b-e139-461e-854a-0f92cefc7c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "|\"ORDER_ID\"  |\"ORDER_AMOUNT_2D\"  |\"ORDER_DATE\"  |\n",
      "-------------------------------------------------\n",
      "|142337652   |11.53              |2021-12-28    |\n",
      "|142337653   |22.06              |2021-12-28    |\n",
      "|142337654   |3.00               |2021-12-28    |\n",
      "|142337655   |41.35              |2021-12-28    |\n",
      "|142337656   |12.48              |2021-12-28    |\n",
      "|142337657   |10.79              |2021-12-28    |\n",
      "|142337658   |11.41              |2021-12-28    |\n",
      "|142337659   |7.07               |2021-12-28    |\n",
      "|142337660   |11.98              |2021-12-28    |\n",
      "|142337661   |7.57               |2021-12-28    |\n",
      "-------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT \"ORDER_ID\",  CAST (\"ORDER_AMOUNT\" AS NUMBER(36, 2)) AS \"ORDER_AMOUNT_2D\", to_date(\"ORDER_TS\") AS \"ORDER_DATE\" FROM ORDER_HEADER'],\n",
       " 'post_actions': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_df1 = snowpark_header_df.select(F.col(\"ORDER_ID\"),F.col('ORDER_AMOUNT').cast(T.DecimalType(36,2)).alias(\"ORDER_AMOUNT_2D\"),\n",
    "                                      F.to_date(F.col('ORDER_TS')).alias('ORDER_DATE'))\n",
    "header_df1.show()\n",
    "header_df1.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67fc979",
   "metadata": {},
   "source": [
    "We can also include calculated expressions within a select as we can in SQL. For example we can use + - * / ** arithmetic operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4daf5ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "|\"ORDER_ID\"  |\"ORDER_AMOUNT_2D\"  |\"OA_CENTS\"  |\n",
      "-----------------------------------------------\n",
      "|99331505    |32.62              |3262.00     |\n",
      "|99331506    |20.89              |2089.00     |\n",
      "|99331507    |18.72              |1872.00     |\n",
      "|99331508    |26.55              |2655.00     |\n",
      "|99331509    |3.91               |391.00      |\n",
      "|99331510    |9.69               |969.00      |\n",
      "|99331511    |23.08              |2308.00     |\n",
      "|99331512    |4.81               |481.00      |\n",
      "|99331513    |5.65               |565.00      |\n",
      "|99331514    |47.84              |4784.00     |\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "header_df2 = header_df1.select(F.col(\"ORDER_ID\"),F.col('ORDER_AMOUNT_2D'),\n",
    "                              (F.col('ORDER_AMOUNT_2D')*100).alias(\"OA_CENTS\"))\n",
    "header_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52a525-5ce5-4ad3-8f74-436976b53386",
   "metadata": {},
   "source": [
    "Again, switch to Snowsight Query History and see what is going on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf11ed-7630-4f18-a9df-e455cb92e125",
   "metadata": {},
   "source": [
    "### Adding and Removing Columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c88906",
   "metadata": {},
   "source": [
    "To add a new calculated column to a Snowpark DataFrame the **withColumn** or **with_column** method can be used.  *(Cf pysaprk withColumn)*\n",
    "In this example we are adding a new TRUCK column, AGE, that calculates the number of years since the YEAR. \n",
    "Note the use of F.col here - otherwise 'YEAR' could be seen as a string value. One approach is to use built-in Python functions to derive the current year locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e207ac8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRUCK_ID</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ISO_COUNTRY_CODE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>TRUCK_OPENING_DATE</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>2015</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>2004</td>\n",
       "      <td>Freightliner</td>\n",
       "      <td>MT45 Utilimaster</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>P30</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>2010</td>\n",
       "      <td>Custom</td>\n",
       "      <td>Van</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>2010</td>\n",
       "      <td>Airstream</td>\n",
       "      <td>Trailer</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>392</td>\n",
       "      <td>Madrid provincia</td>\n",
       "      <td>ES</td>\n",
       "      <td>2010</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>396</td>\n",
       "      <td>Madrid provincia</td>\n",
       "      <td>ES</td>\n",
       "      <td>2005</td>\n",
       "      <td>Freightliner</td>\n",
       "      <td>MT45 Utilimaster</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>419</td>\n",
       "      <td>Barcelona provincia</td>\n",
       "      <td>ES</td>\n",
       "      <td>2015</td>\n",
       "      <td>Airstream</td>\n",
       "      <td>Trailer</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>427</td>\n",
       "      <td>Cairo Governorate</td>\n",
       "      <td>EG</td>\n",
       "      <td>2005</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>Western Cape</td>\n",
       "      <td>ZA</td>\n",
       "      <td>2009</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TRUCK_ID               REGION ISO_COUNTRY_CODE  YEAR          MAKE  \\\n",
       "0           2           California               US  2015         Ford_   \n",
       "1           3           California               US  2004  Freightliner   \n",
       "2           4           California               US  1997     Chevrolet   \n",
       "3           5           California               US  2010        Custom   \n",
       "4           6           California               US  2010     Airstream   \n",
       "..        ...                  ...              ...   ...           ...   \n",
       "445       392     Madrid provincia               ES  2010         Ford_   \n",
       "446       396     Madrid provincia               ES  2005  Freightliner   \n",
       "447       419  Barcelona provincia               ES  2015     Airstream   \n",
       "448       427    Cairo Governorate               EG  2005         Ford_   \n",
       "449       450         Western Cape               ZA  2009         Ford_   \n",
       "\n",
       "                MODEL TRUCK_OPENING_DATE  AGE  \n",
       "0            Step Van         2015-07-01    8  \n",
       "1    MT45 Utilimaster         2015-11-01   19  \n",
       "2                 P30         2019-02-01   26  \n",
       "3                 Van         2020-04-01   13  \n",
       "4             Trailer         2015-07-01   13  \n",
       "..                ...                ...  ...  \n",
       "445          Step Van         2014-12-29   13  \n",
       "446  MT45 Utilimaster         2014-12-29   18  \n",
       "447           Trailer         2014-12-29    8  \n",
       "448          Step Van         2014-12-29   18  \n",
       "449          Step Van         2014-12-29   14  \n",
       "\n",
       "[450 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "year = datetime.now().year\n",
    "\n",
    "truck_df1 = snowpark_truck_df.select('TRUCK_ID','REGION','ISO_COUNTRY_CODE','YEAR',\n",
    "                                     'MAKE','MODEL','TRUCK_OPENING_DATE')\n",
    "truck_df1 = truck_df1.withColumn('AGE', year - F.col('YEAR'))\n",
    "truck_df1.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4eabd5",
   "metadata": {},
   "source": [
    "The following version pushes the current year 'calculation' down to Snowflake.\n",
    "\n",
    "In this section we show how each new version of the dataframe can replace the previous one by using the same name.\n",
    "This can make sense whilst we build up the dataframe query we really want. However, when we do this across cells and try to rerun just one cell we can get errors if a later statement has altered the structure that an earlier statement relied on.... We avoid that here by redefining truck_df1 from its source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f9905ea-12c7-4e0f-9829-112c3633fae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRUCK_ID</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ISO_COUNTRY_CODE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>TRUCK_OPENING_DATE</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>2015</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>2004</td>\n",
       "      <td>Freightliner</td>\n",
       "      <td>MT45 Utilimaster</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>P30</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>2010</td>\n",
       "      <td>Custom</td>\n",
       "      <td>Van</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>2010</td>\n",
       "      <td>Airstream</td>\n",
       "      <td>Trailer</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>392</td>\n",
       "      <td>Madrid provincia</td>\n",
       "      <td>ES</td>\n",
       "      <td>2010</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>396</td>\n",
       "      <td>Madrid provincia</td>\n",
       "      <td>ES</td>\n",
       "      <td>2005</td>\n",
       "      <td>Freightliner</td>\n",
       "      <td>MT45 Utilimaster</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>419</td>\n",
       "      <td>Barcelona provincia</td>\n",
       "      <td>ES</td>\n",
       "      <td>2015</td>\n",
       "      <td>Airstream</td>\n",
       "      <td>Trailer</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>427</td>\n",
       "      <td>Cairo Governorate</td>\n",
       "      <td>EG</td>\n",
       "      <td>2005</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>Western Cape</td>\n",
       "      <td>ZA</td>\n",
       "      <td>2009</td>\n",
       "      <td>Ford_</td>\n",
       "      <td>Step Van</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TRUCK_ID               REGION ISO_COUNTRY_CODE  YEAR          MAKE  \\\n",
       "0           2           California               US  2015         Ford_   \n",
       "1           3           California               US  2004  Freightliner   \n",
       "2           4           California               US  1997     Chevrolet   \n",
       "3           5           California               US  2010        Custom   \n",
       "4           6           California               US  2010     Airstream   \n",
       "..        ...                  ...              ...   ...           ...   \n",
       "445       392     Madrid provincia               ES  2010         Ford_   \n",
       "446       396     Madrid provincia               ES  2005  Freightliner   \n",
       "447       419  Barcelona provincia               ES  2015     Airstream   \n",
       "448       427    Cairo Governorate               EG  2005         Ford_   \n",
       "449       450         Western Cape               ZA  2009         Ford_   \n",
       "\n",
       "                MODEL TRUCK_OPENING_DATE  AGE  \n",
       "0            Step Van         2015-07-01    8  \n",
       "1    MT45 Utilimaster         2015-11-01   19  \n",
       "2                 P30         2019-02-01   26  \n",
       "3                 Van         2020-04-01   13  \n",
       "4             Trailer         2015-07-01   13  \n",
       "..                ...                ...  ...  \n",
       "445          Step Van         2014-12-29   13  \n",
       "446  MT45 Utilimaster         2014-12-29   18  \n",
       "447           Trailer         2014-12-29    8  \n",
       "448          Step Van         2014-12-29   18  \n",
       "449          Step Van         2014-12-29   14  \n",
       "\n",
       "[450 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truck_df1 = snowpark_truck_df.select('TRUCK_ID','REGION','ISO_COUNTRY_CODE','YEAR',\n",
    "                                     'MAKE','MODEL','TRUCK_OPENING_DATE')\n",
    "truck_df1 = truck_df1.withColumn('AGE', F.date_part(\"year\", F.current_date()) - F.col('YEAR'))\n",
    "truck_df1.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c380a5-15dc-46b4-9733-4118d0f36f18",
   "metadata": {},
   "source": [
    "If we do not want to use specific columns we can use **drop** to remove those from a Snowpark DataFrame.  \n",
    "**Note:** This is not removing them from the underlying table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b6057de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "|\"TRUCK_ID\"  |\"REGION\"    |\"ISO_COUNTRY_CODE\"  |\"MAKE\"        |\"TRUCK_OPENING_DATE\"  |\"AGE\"  |\n",
      "----------------------------------------------------------------------------------------------\n",
      "|2           |California  |US                  |Ford_         |2015-07-01            |8      |\n",
      "|3           |California  |US                  |Freightliner  |2015-11-01            |19     |\n",
      "|4           |California  |US                  |Chevrolet     |2019-02-01            |26     |\n",
      "|5           |California  |US                  |Custom        |2020-04-01            |13     |\n",
      "|6           |California  |US                  |Airstream     |2015-07-01            |13     |\n",
      "|7           |California  |US                  |Custom        |2019-02-01            |13     |\n",
      "|8           |California  |US                  |Chevrolet     |2023-03-01            |24     |\n",
      "|9           |California  |US                  |Custom        |2015-07-01            |15     |\n",
      "|10          |California  |US                  |Ford_         |2016-01-01            |14     |\n",
      "|12          |California  |US                  |Custom        |2015-06-01            |13     |\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop a column\n",
    "truck_df1 = truck_df1.drop('MODEL','YEAR')\n",
    "truck_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed84d6-3778-42cc-8dbe-87f78c81fccd",
   "metadata": {},
   "source": [
    "## 1.4 Simple Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea617ddf",
   "metadata": {},
   "source": [
    "### Filtering Rows\n",
    "To filter/select specific rows we use **filter**.\n",
    "A whole set of column operators are available to be used e.g. \n",
    "\n",
    "==, !=, <, <=, >, >=  for comparisons;   &, |  and or;  + - * / **  arithmetic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7abe304d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------\n",
      "|\"TRUCK_ID\"  |\"REGION\"        |\"ISO_COUNTRY_CODE\"  |\"MAKE\"        |\"TRUCK_OPENING_DATE\"  |\"AGE\"  |\n",
      "--------------------------------------------------------------------------------------------------\n",
      "|121         |Greater London  |GB                  |Ford_         |2017-04-01            |9      |\n",
      "|122         |Greater London  |GB                  |Ford_         |2015-10-01            |16     |\n",
      "|123         |Greater London  |GB                  |Ford_         |2018-01-01            |9      |\n",
      "|124         |Greater London  |GB                  |Freightliner  |2022-01-01            |22     |\n",
      "|125         |Greater London  |GB                  |Ford_         |2015-10-01            |9      |\n",
      "|126         |Greater London  |GB                  |Ford_         |2018-02-01            |16     |\n",
      "|127         |Greater London  |GB                  |Ford_         |2015-08-01            |9      |\n",
      "|128         |Greater London  |GB                  |Freightliner  |2015-07-01            |22     |\n",
      "|129         |Greater London  |GB                  |Ford_         |2018-01-01            |13     |\n",
      "|130         |Greater London  |GB                  |Chevrolet     |2022-04-01            |26     |\n",
      "--------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "|\"TRUCK_ID\"  |\"REGION\"          |\"ISO_COUNTRY_CODE\"  |\"MAKE\"        |\"TRUCK_OPENING_DATE\"  |\"AGE\"  |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "|398         |Madrid provincia  |ES                  |Freightliner  |2017-01-01            |18     |\n",
      "|395         |Madrid provincia  |ES                  |Citroën       |2023-01-01            |45     |\n",
      "|393         |Madrid provincia  |ES                  |Freightliner  |2021-10-01            |22     |\n",
      "|401         |Madrid provincia  |ES                  |Ford_         |2015-10-01            |9      |\n",
      "|399         |Madrid provincia  |ES                  |Freightliner  |2019-07-01            |18     |\n",
      "|394         |Madrid provincia  |ES                  |Freightliner  |2015-10-01            |23     |\n",
      "|391         |Madrid provincia  |ES                  |Chevrolet     |2023-01-01            |26     |\n",
      "|402         |Madrid provincia  |ES                  |Airstream     |2015-08-01            |13     |\n",
      "|400         |Madrid provincia  |ES                  |Ford_         |2022-01-01            |9      |\n",
      "|397         |Madrid provincia  |ES                  |Freightliner  |2015-08-01            |18     |\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|\"TRUCK_ID\"  |\"REGION\"       |\"ISO_COUNTRY_CODE\"  |\"MAKE\"        |\"TRUCK_OPENING_DATE\"  |\"AGE\"  |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "|151         |Île-de-France  |FR                  |Custom        |2018-01-01            |15     |\n",
      "|152         |Île-de-France  |FR                  |Ford_         |2015-02-01            |9      |\n",
      "|153         |Île-de-France  |FR                  |Ford_         |2017-04-01            |16     |\n",
      "|154         |Île-de-France  |FR                  |Ford_         |2015-10-01            |9      |\n",
      "|155         |Île-de-France  |FR                  |Freightliner  |2023-01-01            |18     |\n",
      "|156         |Île-de-France  |FR                  |Freightliner  |2015-02-01            |18     |\n",
      "|157         |Île-de-France  |FR                  |Airstream     |2018-10-01            |13     |\n",
      "|158         |Île-de-France  |FR                  |Freightliner  |2020-07-01            |18     |\n",
      "|159         |Île-de-France  |FR                  |Ford_         |2015-08-01            |9      |\n",
      "|160         |Île-de-France  |FR                  |Freightliner  |2018-01-01            |18     |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT \"TRUCK_ID\", \"REGION\", \"ISO_COUNTRY_CODE\", \"MAKE\", \"TRUCK_OPENING_DATE\", (date_part(\\'year\\', current_date()) - \"YEAR\") AS \"AGE\" FROM TRUCK WHERE \"ISO_COUNTRY_CODE\" IN (\\'ES\\', \\'FR\\', \\'GB\\') ORDER BY \"ISO_COUNTRY_CODE\" ASC NULLS FIRST'],\n",
       " 'post_actions': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter data\n",
    "truck_df2 = truck_df1.filter(F.col('ISO_COUNTRY_CODE') == 'GB')\n",
    "truck_df2.show()\n",
    "truck_df3 = truck_df1.filter(F.col('ISO_COUNTRY_CODE').in_('ES','FR','GB')).sort('ISO_COUNTRY_CODE')\n",
    "truck_df3.show()\n",
    "truck_df4 = truck_df1.filter(F.col('ISO_COUNTRY_CODE').like('F%'))\n",
    "truck_df4.show()\n",
    "truck_df3.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc21227",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "We may want to see data in a specific order. For this the **sort** method is used..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2196027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "|\"TRUCK_ID\"  |\"REGION\"                    |\"ISO_COUNTRY_CODE\"  |\"MAKE\"        |\"TRUCK_OPENING_DATE\"  |\"AGE\"  |\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "|163         |Île-de-France               |FR                  |Freightliner  |2023-01-01            |18     |\n",
      "|165         |Île-de-France               |FR                  |Freightliner  |2023-01-01            |22     |\n",
      "|168         |Provence–Alpes–Côte-d'Azur  |FR                  |Chevrolet     |2023-01-01            |24     |\n",
      "|155         |Île-de-France               |FR                  |Freightliner  |2023-01-01            |18     |\n",
      "|176         |Provence–Alpes–Côte-d'Azur  |FR                  |Freightliner  |2021-10-01            |22     |\n",
      "|158         |Île-de-France               |FR                  |Freightliner  |2020-07-01            |18     |\n",
      "|157         |Île-de-France               |FR                  |Airstream     |2018-10-01            |13     |\n",
      "|166         |Provence–Alpes–Côte-d'Azur  |FR                  |Freightliner  |2018-10-01            |22     |\n",
      "|170         |Provence–Alpes–Côte-d'Azur  |FR                  |Ford_         |2018-10-01            |9      |\n",
      "|151         |Île-de-France               |FR                  |Custom        |2018-01-01            |15     |\n",
      "|160         |Île-de-France               |FR                  |Freightliner  |2018-01-01            |18     |\n",
      "|169         |Provence–Alpes–Côte-d'Azur  |FR                  |Ford_         |2018-01-01            |11     |\n",
      "|153         |Île-de-France               |FR                  |Ford_         |2017-04-01            |16     |\n",
      "|175         |Provence–Alpes–Côte-d'Azur  |FR                  |Freightliner  |2017-04-01            |22     |\n",
      "|178         |Provence–Alpes–Côte-d'Azur  |FR                  |Freightliner  |2016-07-01            |22     |\n",
      "|174         |Provence–Alpes–Côte-d'Azur  |FR                  |Airstream     |2015-10-01            |13     |\n",
      "|179         |Provence–Alpes–Côte-d'Azur  |FR                  |Ford_         |2015-10-01            |14     |\n",
      "|161         |Île-de-France               |FR                  |Ford_         |2015-10-01            |11     |\n",
      "|154         |Île-de-France               |FR                  |Ford_         |2015-10-01            |9      |\n",
      "|167         |Provence–Alpes–Côte-d'Azur  |FR                  |Ford_         |2015-10-01            |9      |\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort data\n",
    "truck_df4 = truck_df4.sort(F.col('TRUCK_OPENING_DATE').desc(),F.col('ISO_COUNTRY_CODE'))\n",
    "truck_df4.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad49ef-2ddb-4322-8ef3-c2c81e9ce1c8",
   "metadata": {},
   "source": [
    "### Aggregation\n",
    "To aggregate data the **groupBy** or **group_by** method is typically used. The groupby method produces a RelationalGroupedDataFrame object with its own specific methods, which, in turn, return a DataFrame. The **agg** method provides the most flexibility for managing the output, and including different aggregate metrics for different columns. Note the syntax - although operating on columns, the functions like avg expect the string of the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a56c822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT  *  FROM ( SELECT \"ISO_COUNTRY_CODE\", \"MAKE\", count(1) AS \"COUNT\", avg(\"AGE\") AS \"AVG_TRUCK_AGE\", max(\"TRUCK_ID\") AS \"MAX_TRUCK_ID\" FROM ( SELECT \"TRUCK_ID\", \"REGION\", \"ISO_COUNTRY_CODE\", \"MAKE\", \"TRUCK_OPENING_DATE\", (date_part(\\'year\\', current_date()) - \"YEAR\") AS \"AGE\" FROM TRUCK WHERE \"ISO_COUNTRY_CODE\" IN (\\'ES\\', \\'FR\\', \\'GB\\') ORDER BY \"ISO_COUNTRY_CODE\" ASC NULLS FIRST) GROUP BY \"ISO_COUNTRY_CODE\", \"MAKE\") ORDER BY \"ISO_COUNTRY_CODE\" ASC NULLS FIRST, \"COUNT\" DESC NULLS LAST'],\n",
       " 'post_actions': []}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truck_df5 = truck_df3.groupBy(['ISO_COUNTRY_CODE','MAKE']).agg(\n",
    "             [F.count('*').alias('COUNT'),F.avg('AGE').alias('AVG_TRUCK_AGE'),F.max('TRUCK_ID').alias('MAX_TRUCK_ID')])\n",
    "truck_df5 = truck_df5.sort(F.col('ISO_COUNTRY_CODE'), F.col('COUNT').desc())\n",
    "truck_df5.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf7f204e-6443-4625-b1ab-c567addac20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "|\"ISO_COUNTRY_CODE\"  |\"MAKE\"        |\"COUNT\"  |\"AVG_TRUCK_AGE\"  |\"MAX_TRUCK_ID\"  |\n",
      "----------------------------------------------------------------------------------\n",
      "|ES                  |Freightliner  |12       |19.416667        |417             |\n",
      "|ES                  |Ford_         |8        |12.750000        |418             |\n",
      "|ES                  |Airstream     |2        |10.500000        |419             |\n",
      "|ES                  |Custom        |2        |14.000000        |420             |\n",
      "|ES                  |Chevrolet     |2        |26.000000        |404             |\n",
      "|ES                  |Citroën       |2        |43.500000        |415             |\n",
      "|ES                  |Volkswagen    |1        |51.000000        |403             |\n",
      "|ES                  |Nissan        |1        |5.000000         |414             |\n",
      "|FR                  |Freightliner  |13       |19.538462        |178             |\n",
      "|FR                  |Ford_         |10       |10.800000        |179             |\n",
      "|FR                  |Airstream     |4        |13.000000        |180             |\n",
      "|FR                  |Chevrolet     |1        |24.000000        |168             |\n",
      "|FR                  |Nissan        |1        |5.000000         |162             |\n",
      "|FR                  |Custom        |1        |15.000000        |151             |\n",
      "|GB                  |Ford_         |16       |11.500000        |150             |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truck_df5.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb2710-ff89-492a-b80c-032b897afbbe",
   "metadata": {},
   "source": [
    "### Using SQL\n",
    "How might we express the same combined query in SQL? It is quite likely that we would want to break it down in a similar way.\n",
    "We can run SQL queries directly using **session.sql** (including Snowflake commands issued as SQL). \n",
    "Note that nothing will happen without a collect() or show().\n",
    "\n",
    "In the example below, the three quotes beginning and end are how we indicate a multi-line string in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "367ebc20-57d6-47f1-957a-fc095798cd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "|\"ISO_COUNTRY_CODE\"  |\"MAKE\"        |\"COUNT\"  |\"AVG_TRUCK_AGE\"  |\"MAX_TRUCK_ID\"  |\n",
      "----------------------------------------------------------------------------------\n",
      "|ES                  |Freightliner  |12       |19.416667        |417             |\n",
      "|ES                  |Ford_         |8        |12.750000        |418             |\n",
      "|ES                  |Citroën       |2        |43.500000        |415             |\n",
      "|ES                  |Custom        |2        |14.000000        |420             |\n",
      "|ES                  |Airstream     |2        |10.500000        |419             |\n",
      "|ES                  |Chevrolet     |2        |26.000000        |404             |\n",
      "|ES                  |Volkswagen    |1        |51.000000        |403             |\n",
      "|ES                  |Nissan        |1        |5.000000         |414             |\n",
      "|FR                  |Freightliner  |13       |19.538462        |178             |\n",
      "|FR                  |Ford_         |10       |10.800000        |179             |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'queries': [\"SELECT ISO_COUNTRY_CODE, MAKE, count(1) AS COUNT, avg(AGE) AS AVG_TRUCK_AGE, max(TRUCK_ID) AS MAX_TRUCK_ID \\n   FROM ( SELECT TRUCK_ID, REGION, ISO_COUNTRY_CODE, MAKE, TRUCK_OPENING_DATE, (date_part('year', current_date()) - YEAR) AS AGE \\n       FROM TRUCK WHERE ISO_COUNTRY_CODE IN ('ES', 'FR', 'GB')\\n     ) \\n   GROUP BY ISO_COUNTRY_CODE, MAKE ORDER BY ISO_COUNTRY_CODE ASC NULLS FIRST, COUNT DESC NULLS LAST LIMIT 15\"],\n",
       " 'post_actions': []}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truck_df6 = session.sql(\"\"\"\n",
    " SELECT ISO_COUNTRY_CODE, MAKE, count(1) AS COUNT, avg(AGE) AS AVG_TRUCK_AGE, max(TRUCK_ID) AS MAX_TRUCK_ID \n",
    "   FROM ( SELECT TRUCK_ID, REGION, ISO_COUNTRY_CODE, MAKE, TRUCK_OPENING_DATE, (date_part('year', current_date()) - YEAR) AS AGE \n",
    "       FROM TRUCK WHERE ISO_COUNTRY_CODE IN ('ES', 'FR', 'GB')\n",
    "     ) \n",
    "   GROUP BY ISO_COUNTRY_CODE, MAKE ORDER BY ISO_COUNTRY_CODE ASC NULLS FIRST, COUNT DESC NULLS LAST LIMIT 15\n",
    "   \"\"\")\n",
    "truck_df6.show()\n",
    "truck_df6.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c3a6a",
   "metadata": {},
   "source": [
    "## 1.5 Persist Transformations\n",
    "\n",
    "If we want to save the changes we can either save it as a table, meaning the SQL generated by the DataFrame is executed and the result is stored in a table or as a view where the DataFrame SQL will be the definition of the view.  \n",
    "**save_as_table** saves the result in a table, if **mode='overwrite'** then it will also replace the data that is in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "995c4a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------\n",
      "|\"TRUCK_ID\"  |\"REGION\"             |\"ISO_COUNTRY_CODE\"  |\"MAKE\"        |\"TRUCK_OPENING_DATE\"  |\"AGE\"  |\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "|419         |Barcelona provincia  |ES                  |Airstream     |2014-12-29            |8      |\n",
      "|391         |Madrid provincia     |ES                  |Chevrolet     |2023-01-01            |26     |\n",
      "|393         |Madrid provincia     |ES                  |Freightliner  |2021-10-01            |22     |\n",
      "|394         |Madrid provincia     |ES                  |Freightliner  |2015-10-01            |23     |\n",
      "|395         |Madrid provincia     |ES                  |Citroën       |2023-01-01            |45     |\n",
      "|397         |Madrid provincia     |ES                  |Freightliner  |2015-08-01            |18     |\n",
      "|398         |Madrid provincia     |ES                  |Freightliner  |2017-01-01            |18     |\n",
      "|399         |Madrid provincia     |ES                  |Freightliner  |2019-07-01            |18     |\n",
      "|400         |Madrid provincia     |ES                  |Ford_         |2022-01-01            |9      |\n",
      "|401         |Madrid provincia     |ES                  |Ford_         |2015-10-01            |9      |\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truck_df3.write.save_as_table(table_name='TRUCK_ANALYSIS', mode='overwrite')\n",
    "session.table('TRUCK_ANALYSIS').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46de37-0442-4452-a64b-766dfc4c9914",
   "metadata": {},
   "source": [
    "## 1.X YOUR TURN!\n",
    "\n",
    "Here is the challenge: Generate a list of months for which we have data, the total order amount for each month (assume amounts are all held in the same currency), and the number of distinct locations visted in each month.\n",
    "<br>Hints:\n",
    "Functions you may find useful include **count_distinct** (aka countDistinct), **date_part**, **to_char** with numeric formatting '09' or 'FM09' and **concat**.\n",
    "\n",
    "### Hint:   \n",
    "To see all methods available use the TAB key.    F.<TAB>   Will show all functon methods.\n",
    "\n",
    "To see for a specific function the help text.   SHIFT-TAB\n",
    "                                                                                                                                                      \n",
    "https://docs.snowflake.com/developer-guide/snowpark/reference/scala/com/snowflake/snowpark/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80c981",
   "metadata": {},
   "source": [
    "### Check out the data\n",
    "\n",
    "What columns in Order Header will you need?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e604fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f4eaceb-b960-4103-84b6-c96baf2ae849",
   "metadata": {},
   "source": [
    "### Select the columns you need and create a Month column\n",
    "You'll need to concatenate the year and month date parts of the order timestamp.\n",
    "Note that (currently) date_format in Snowpark is an alias of to_date and not the date to string functionality of Pyspark..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd3a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5e7eb-988e-49a2-ac6e-55825fe5419f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc09aaf8",
   "metadata": {},
   "source": [
    "### Now aggregate by month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd7e50-4eb4-47e3-af53-3ca409bf74cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7287f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16aaa4a-d4f3-4cc4-ae8e-bea4cf1683d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5bada-efaa-43ea-a5f7-3f8006c35bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
